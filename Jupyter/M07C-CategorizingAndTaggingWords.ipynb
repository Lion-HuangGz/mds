{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FLIP(01):  Advanced Data Science\n",
    "**(Module 7: Natural Language Processing)**\n",
    "\n",
    "---\n",
    "- Materials in this module include resources collected from various open-source online repositories.\n",
    "- You are free to use, but NOT allowed to change or distribute this package.\n",
    "\n",
    "Prepared by and for \n",
    "**Student Members** |\n",
    "2006-2019 [TULIP Lab](http://www.tulip.org.au)\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "# Session C - Categorizing and Tagging Words \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "\n",
    "1 [Using a Tagger](#Tagger)\n",
    "\n",
    "2 [Tagged Corpora](#Corpora)\n",
    "\n",
    "3 [Default Tagger](#Default)\n",
    "\n",
    "4 [Query Tagger](#Query)\n",
    "\n",
    "5 [Unigram Tagger](#Unigram)\n",
    "\n",
    "6 [Bigram Tagger](#Bigram)\n",
    "\n",
    "7 [Combining Tagger](#Combining)\n",
    "\n",
    "8.[Summary](#Summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"Tagger\"></a>\n",
    "\n",
    "## <span style=\"color:#0b486b\">1. Using a Tagger</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tagger processes a sequence of words and appends a part-of-speech tag to each word. Let's look at an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "words = nltk.word_tokenize('And now for something completely different')\n",
    "print words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_tag = nltk.pos_tag(words)\n",
    "print word_tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Nltk.word_tokenize(text)`: Segments the specified sentence and returns a list of words.\n",
    "\n",
    "`Nltk.pos_tag(words)`: Attributes the specified word list and returns a list of tags.\n",
    "\n",
    "From the results we can see that something is NN, NN means noun."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"Corpora\"></a>\n",
    "\n",
    "## <span style=\"color:#0b486b\">2. Tagged Corpora</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many corpora in NLTK have been labeled with part of speech. The Brown corpus we have studied before is a corpus with word-of-speech, and the semaphores used in each corpus can be different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import brown\n",
    "words_tag = brown.tagged_words(categories='news')\n",
    "print words_tag[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Brown can be thought of as a CategorizedTaggedCorpusReader instance object.\n",
    "\n",
    "`CategorizedTaggedCorpusReader::tagged_words(fileids, categories)`: this method accepts a text identifier or a category identifier as a parameter, and returns a list of words whose words are tagged with part of speech.\n",
    "\n",
    "`CategorizedTaggedCorpusReader::tagged_sents(fileids, categories)`: this method accepts a text identifier or a category identifier as a parameter, and returns a list of sentences after the text is tagged with the part of speech, and the sentence is a list of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tagged_sents = brown.tagged_sents(categories='news')\n",
    "print tagged_sents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLTK also contains a Chinese corpus `sinica_treebank`, which uses Traditional Chinese. The library is also labeled with part of speech. Let's take a look at the library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import sinica_treebank\n",
    "print sinica_treebank.fileids()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Sinica_treebank` can be thought of as a SinicaTreebankCorpusReader instance object.\n",
    "\n",
    "`SinicaTreebankCorpusReader::words(fileids)`: This method takes a text identifier as a parameter and returns a list of words in the text.\n",
    "\n",
    "`SinicaTreebankCorpusReader::tagged_words(fileids)`: This method accepts the text identifier as a parameter and returns a list of words whose text is tagged with part of speech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "words = sinica_treebank.words('parsed')\n",
    "print words[:40]\n",
    "words_tag = sinica_treebank.tagged_words('parsed')\n",
    "print words_tag[:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "words_tag = sinica_treebank.tagged_words('parsed')\n",
    "tag_fd = nltk.FreqDist(tag for (word, tag) in words_tag)\n",
    "tag_fd.tabulate(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"Default\"></a>\n",
    "\n",
    "## <span style=\"color:#0b486b\">3. Default Tagger</span>\n",
    "\n",
    "The default tagger assigns the same token to each word, although it is mediocre, but it also works. Let's look at the example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "raw = \"You are a good man, but i don't love you!\"\n",
    "tokens = nltk.word_tokenize(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "default_tagger = nltk.DefaultTagger('NN')\n",
    "tagged_words = default_tagger.tag(tokens)\n",
    "print tagged_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The DefaultTagger constructor takes a tag string as a parameter and generates a default caller object. From the result, you can see that the default tagger marks all words as NN.\n",
    "\n",
    "`DefaultTagger::tag(tokens):` Marks the specified word list and returns the list of words after the tag.\n",
    "`DefaultTagger::evaluete(tagged_sents):` Evaluate the annotator with a sentence that has already been marked, returning a correct rate of 0~1.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import brown\n",
    "tagged_sents = brown.tagged_sents(categories='news')\n",
    "print default_tagger.evaluate(tagged_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the default tagger we created ourselves is only correct at 0.13."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"Query\"></a>\n",
    "\n",
    "## <span style=\"color:#0b486b\">4. Query Tagger</span>\n",
    "\n",
    "The default tagger uses the same tag for all words, and the accuracy is too low. We can consider specifying different words as different tags. Let's look at an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Frequency distribution of news texts to find the 100 most commonly used words in news text\n",
    "fd = nltk.FreqDist(brown.words(categories='news'))\n",
    "most_common_pairs = fd.most_common(100)\n",
    "most_common_words = [i[0] for i in most_common_pairs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "most_common_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cfd = nltk.ConditionalFreqDist(brown.tagged_words(categories='news'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cfd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "likely_tags = dict((word, cfd[word].max()) for word in most_common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "likely_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "baseline_tagger = nltk.UnigramTagger(model=likely_tags)\n",
    "tagged_sents = brown.tagged_sents(categories='news')\n",
    "print(baseline_tagger.evaluate(tagged_sents))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correctness of the tagger we created this time is 0.45, which is much better than our default tagger. The constructor of the `UnigramTagger` class accepts a (word-to-tagger) dictionary as a model and can directly generate an tagger. In fact, both the `UnigramTagger` and the `DefaultTagger` classes inherit from `TaggerI`, which has tag and evaluete methods, so `UnigramTagger` also has tag and evaluete methods.\n",
    "\n",
    "Since we only specified the markup of 100 words, let's see how the tagger we created is labeled for unspecified words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "raw = \"You are a good man, but i don't love you!\"\n",
    "tokens = nltk.word_tokenize(raw)\n",
    "print baseline_tagger.tag(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many words are assigned as None tags because they are not included in 100 words. In this case, we can give them a default tag. In other words, we need to use the lookup table first. If it can't specify a tag, we use the default tagger. This process is called rollback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "baseline_tagger2 = nltk.UnigramTagger(model=likely_tags, backoff=nltk.DefaultTagger('NN'))\n",
    "tagged_sents = brown.tagged_sents(categories='news')\n",
    "print baseline_tagger2.evaluate(tagged_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the correct rate has improved.\n",
    "If we increase the number of words, the correct rate will increase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fd = nltk.FreqDist(brown.words(categories='news'))\n",
    "most_common_pairs = fd.most_common(500)\n",
    "most_common_words = [i[0] for i in most_common_pairs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "most_common_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cfd = nltk.ConditionalFreqDist(brown.tagged_words(categories='news'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "likely_tags = dict((word, cfd[word].max()) for word in most_common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "baseline_tagger = nltk.UnigramTagger(model=likely_tags, backoff=nltk.DefaultTagger('NN'))\n",
    "tagged_sents = brown.tagged_sents(categories='news')\n",
    "print baseline_tagger.evaluate(tagged_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"Unigram\"></a>\n",
    "\n",
    "## <span style=\"color:#0b486b\">5. Unigram Tagger</span>\n",
    "\n",
    "The unigram taggeing is based on a simple statistical algorithm: assign each word the most likely mark of the word. The unary annotator behaves like a query annotator, but it doesn't require us to provide a model. We only need to provide a training sample, which is a list of marked sentences. The annotator will use these samples for training, and the most likely mark for all words. Stored in a dictionary, examples are as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "tagged_sents = brown.tagged_sents(categories='news')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unigram_tagger = nltk.UnigramTagger(train=tagged_sents)\n",
    "print unigram_tagger.evaluate(tagged_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This result is much better than our previous query tagger, and the unigram tagger does not require us to count the most likely tags for each word.\n",
    "\n",
    "However, it is not a good practice to use the same data set as the training set and test set. If we train the tagging over-fitting we can't know, then we need to separate the training set and test set, we put the data set 90% is used as a training set and 10% is used as a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tagged_sents = brown.tagged_sents(categories='news')\n",
    "size = int(len(tagged_sents) * 0.9)\n",
    "train_sets = tagged_sents[:size]\n",
    "test_sets = tagged_sents[size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unigram_tagger = nltk.UnigramTagger(train=train_sets)\n",
    "print unigram_tagger.evaluate(train_sets)\n",
    "print unigram_tagger.evaluate(test_sets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the accuary rate of the Unigram Tagging on the test set is 0.81."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"Bigram\"></a>\n",
    "\n",
    "## <span style=\"color:#0b486b\">6. Bigram Tagger</span>\n",
    "\n",
    "Although we assign each word the most likely mark of this identifier, in different contexts, the word is likely to be other tags. So the mark of a word is not only related to itself, but also to its previous word or to a preceding word. The bigram taggers is an tagger that considers the word itself and the previous word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tagged_sents = brown.tagged_sents(categories='news')\n",
    "size = int(len(tagged_sents) * 0.9)\n",
    "train_sets = tagged_sents[:size]\n",
    "test_sets = tagged_sents[size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bigram_tagger = nltk.BigramTagger(train=train_sets)\n",
    "print bigram_tagger.evaluate(train_sets)\n",
    "print bigram_tagger.evaluate(test_sets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bigram taggers will examine the word itself and the mark of its previous word. If a new word is encountered, the bigram taggers can't mark it, and it will cause the next word to be unmarked, so we will see that the bigram taggers has a low accuracy on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"Combining\"></a>\n",
    "\n",
    "## <span style=\"color:#0b486b\">7. Combining Tagger</span>\n",
    "\n",
    "In the previous, we set a backing taggers (the default taggers) for the query taggers. In fact, most NLTK taggers can set the rewinding taggers, so that we can put the bigram taggers, the unigram taggers, and the default. The taggers combine to get a combining taggers, for example we can combine in the following ways:\n",
    "\n",
    "1. Try tagging the token with the bigram tagger.\n",
    "2. If the bigram tagger is unable fo find a tag for the token, try the unigram tagger.\n",
    "3. If the unigram tagger is also unable to find a tag, use a default tagger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tagged_sents = brown.tagged_sents(categories='news')\n",
    "size = int(len(tagged_sents) * 0.9)\n",
    "train_sets = tagged_sents[:size]\n",
    "test_sets = tagged_sents[size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t0 = nltk.DefaultTagger('NN')\n",
    "t1 = nltk.UnigramTagger(train=train_sets, backoff=t0)\n",
    "t2 = nltk.BigramTagger(train=train_sets, backoff=t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print t2.evaluate(train_sets)\n",
    "print t2.evaluate(test_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tag import UnigramTagger\n",
    "from nltk.corpus import treebank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training = treebank.tagged_sents()[:7000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unitagger = UnigramTagger(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "treebank.sents()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unitagger.tag(treebank.sents()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testing = treebank.tagged_sents()[2000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unitagger.evaluate(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sent = [(\"A\",\"DT\"),(\"wise\",\"JJ\"),(\"small\",\"JJ\"),(\"girl\",\"NN\"),(\"of\",\"IN\"),(\"village\",\"NN\"),(\"became\",\"VBD\"),(\"leader\",\"NN\")]\n",
    "grammar = \"NP: {<DT>?<JJ>*<NN><IN>?<NN>*}\"\n",
    "find = nltk.RegexpParser(grammar)\n",
    "res = find.parse(sent)\n",
    "print res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"Summary\"></a>\n",
    "\n",
    "## <span style=\"color:#0b486b\">7. Summary</span>\n",
    "\n",
    "* `nltk.word_tokenize（text）:` Classify the specified sentence, return a list of words\n",
    "* `Nltk.pos_tag(words):` token-based tagging the specified word list, returning the tag list\n",
    "\n",
    "* `CategorizedTaggedCorpusReader::tagged_words(fileids, categories):` This method accepts a text identifier or a category identifier as a parameter, and returns a list of words after the text is tagged with part of speech.\n",
    "\n",
    "* `CategorizedTaggedCorpusReader::tagged_sents(fileids, categories):` This method accepts the text identifier or category identifier as a parameter, and returns a list of sentences after the text is tagged with the part of speech. The sentence is a list of words.\n",
    "\n",
    "* `SinicaTreebankCorpusReader::tagged_words(fileids):` This method accepts the text identifier as a parameter and returns the list of words after the text is tagged with part of speech.\n",
    "\n",
    "* `SinicaTreebankCorpusReader::tagged_sents(fileids):` This method accepts the text identifier as a parameter, and returns a list of sentences after the text is tagged with the part of speech. The sentence is a list of words."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [py2]",
   "language": "python",
   "name": "Python [py2]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

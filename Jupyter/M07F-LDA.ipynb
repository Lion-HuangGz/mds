{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modern Data Science\n",
    "**(Module 07: Natural Language Processing)**\n",
    "\n",
    "---\n",
    "- Materials in this module include resources collected from various open-source online repositories.\n",
    "- You are free to use, change and distribute this package.\n",
    "- If you found any issue/bug for this document, please submit an issue at [tulip-lab/mds](https://github.com/tulip-lab/mds/issues)\n",
    "\n",
    "Prepared by and for \n",
    "**Student Members** |\n",
    "2006-2019 [TULIP Lab](http://www.tulip.org.au)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session F - Topic Model - LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"Computing\"></a>\n",
    "\n",
    "## <span style=\"color:#0b486b\">Import the packages</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# !pip install textblob\n",
    "# !pip install ftfy\n",
    "!pip install pyLDAvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk import stem,pos_tag\n",
    "import re\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "%pylab inline\n",
    "from textblob import TextBlob\n",
    "from sklearn.metrics import silhouette_score,confusion_matrix,accuracy_score,roc_curve\n",
    "import pandas as pd\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import label_binarize,Normalizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from scipy import interp\n",
    "import ftfy\n",
    "import pyLDAvis.sklearn\n",
    "pyLDAvis.enable_notebook()\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "import statsmodels.api as sm\n",
    "from seaborn import lmplot\n",
    "import os  # for os.path.basename\n",
    "import matplotlib as mpl\n",
    "from sklearn.manifold import MDS,TSNE\n",
    "%pylab inline\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.utils.extmath import density\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.decomposition import TruncatedSVD,PCA,NMF\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.decomposition.online_lda import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"Function\"></a>\n",
    "\n",
    "## <span style=\"color:#0b486b\">Function to get titles of talks</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_titles_from_talks(talks):\n",
    "    \n",
    "    title = []\n",
    "    # For all the talks in that category\n",
    "    for talk in talks:\n",
    "        # if the talk is not empty\n",
    "        if talk != \"\":\n",
    "            # split talk and the header\n",
    "            h,s = talk.lower().split(\"\\n\\n\")\n",
    "            # Header contains the title and the number of views\n",
    "            t,v = h.split(\"\\n\")\n",
    "            # Get the titles\n",
    "            title.append(t)\n",
    "    return title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pip install wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import wget\n",
    "\n",
    "entertainment = 'https://github.com/tulip-lab/mds/tree/master/Jupyter/data/entertainment.txt?raw=true'\n",
    "entertainment = wget.download(entertainment) \n",
    "\n",
    "technology = 'https://github.com/tulip-lab/mds/tree/master/Jupyter/data/technology.txt?raw=true'\n",
    "technology = wget.download(technology) \n",
    "\n",
    "science  = 'https://github.com/tulip-lab/mds/tree/master/Jupyter/data/science.txt?raw=true'\n",
    "science = wget.download(science) \n",
    "\n",
    "business = 'https://github.com/tulip-lab/mds/tree/master/Jupyter/data/business.txt?raw=true'\n",
    "business = wget.download(business) \n",
    "\n",
    "global_issues = 'https://github.com/tulip-lab/mds/tree/master/Jupyter/data/global_issues.txt?raw=true'\n",
    "global_issues = wget.download(global_issues) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(entertainment, 'r', encoding='utf-8') as f:\n",
    "    talks = ftfy.fix_text(f.read()).split(\"\\n\\n\\n\\n\")\n",
    "    \n",
    "talks= list(set((talks)))\n",
    "       \n",
    "ent = get_titles_from_talks(talks)\n",
    "\n",
    "\n",
    "\n",
    "with open(technology, 'r', encoding='utf-8') as f:\n",
    "    talks = ftfy.fix_text(f.read()).split(\"\\n\\n\\n\\n\")\n",
    "    \n",
    "talks = list(set((talks)))\n",
    "       \n",
    "tech = get_titles_from_talks(talks)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with open(science, 'r', encoding='utf-8') as f:\n",
    "    talks = ftfy.fix_text(f.read()).split(\"\\n\\n\\n\\n\")\n",
    "    \n",
    "talks = list(set((talks)))\n",
    "       \n",
    "science = get_titles_from_talks(talks)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with open(business, 'r', encoding='utf-8') as f:\n",
    "    talks = ftfy.fix_text(f.read()).split(\"\\n\\n\\n\\n\")\n",
    "    \n",
    "talks = list(set((talks)))\n",
    "       \n",
    "business = get_titles_from_talks(talks)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with open(global_issues, 'r', encoding='utf-8') as f:\n",
    "    talks = ftfy.fix_text(f.read()).split(\"\\n\\n\\n\\n\")\n",
    "    \n",
    "talks = list(set((talks)))\n",
    "       \n",
    "glob = get_titles_from_talks(talks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"Getting\"></a>\n",
    "\n",
    "## <span style=\"color:#0b486b\">Getting the talks that occur only once over the whole corpus.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topic_c = Counter()\n",
    "# loop over all the talk-titles in each of the category\n",
    "for topic in [ent,tech,glob,business,science]:\n",
    "    #increment the counter for that title if it occurs more than once\n",
    "    topic_c += Counter(topic)\n",
    "# unzip the counter object\n",
    "topic,c = zip(*topic_c.items())\n",
    "# select the talks that only occur once\n",
    "titles = np.array(topic)[np.where(np.array(c)==1)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### These single letter labels make it easy to unserstand the output in some places\n",
    "\n",
    "s -> science --- 0\n",
    "\n",
    "t -> Technology --- 1\n",
    "\n",
    "b ->business --- 2\n",
    "\n",
    "g ->global --- 3\n",
    "\n",
    "e -> entertainment ---4\n",
    "\n",
    "<a id = \"Creating\"></a>\n",
    "\n",
    "## <span style=\"color:#0b486b\">Creating a dictionary of labels for all the talks</span>\n",
    "\n",
    "\n",
    "### These are the actual labels : I'm getting them beacuse I'm loading talks category wise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = {}\n",
    "\n",
    "for title in titles:\n",
    "    if title in tech:  # Talks in technology  have title \"t\"\n",
    "        d[title]=\"t\"\n",
    "    if title in ent:# Talks in entertainment  have title \"e\"\n",
    "        d[title]=\"e\"\n",
    "    if title in business: # Talks in business  have title \"b\"\n",
    "        d[title]=\"b\"\n",
    "    if title in glob: # Talks in global issues  have title \"g\"\n",
    "        d[title]=\"g\"\n",
    "    if title in science: # Talks in science  have title \"s\"\n",
    "        d[title]=\"s\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"Category\"></a>\n",
    "\n",
    "## <span style=\"color:#0b486b\">Category sizes/splits :</span>\n",
    "\n",
    "business = 123\n",
    "\n",
    "entertainment = 152\n",
    "\n",
    "global issues = 245\n",
    "\n",
    "science = 209\n",
    "\n",
    "technology = 249"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Counter(d.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we donot have much class imbalance. \n",
    "\n",
    "Base line accuracy is 25-30%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"Loading\"></a>\n",
    "\n",
    "## <span style=\"color:#0b486b\">Loading all the documents together, retaining all the punctuations to get a proper count of pauses and question marks for EDA</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "allt =  'https://github.com/tulip-lab/mds/tree/master/Jupyter/data/all.txt?raw=true'\n",
    "allt = wget.download(allt) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Loading the file that contains all the talks. These belong to all the categories that we have\n",
    "with open(allt, 'r', encoding='utf-8') as f:\n",
    "    talks = ftfy.fix_text(f.read()).split(\"\\n\\n\\n\\n\")\n",
    "\n",
    "talks = list(set((talks)))\n",
    "lemma = WordNetLemmatizer()\n",
    "stop_w = stopwords.words(\"english\")\n",
    "views = []\n",
    "speeches = []\n",
    "title = []\n",
    "labels = []\n",
    "senti = []\n",
    "talks.remove(\"\")\n",
    "\n",
    "# loop over talks\n",
    "for talk in talks:\n",
    "    \n",
    "\n",
    "    # Split the header and the actual speech\n",
    "    h,s = talk.lower().split(\"\\n\\n\")\n",
    "    #split the header , that contains title and the views\n",
    "    t,v = h.split(\"\\n\")\n",
    "    # If that title is predent in the talks that are unique , which we computed earlier\n",
    "    if t in d:\n",
    "        # some punctuation removal\n",
    "        s = s.replace(\". \",\" \").replace(\", \",\" \").replace(\",\",\" \").replace(\".\",\" \").replace(\"  \",\" \").replace('\"',\" \")\n",
    "\n",
    "        # removing stop words\n",
    "        s = \" \".join(i for i in s.split() if i not in stop_w)\n",
    "        \n",
    "        f = TextBlob(s)\n",
    "        senti.append(f.polarity)\n",
    "        \n",
    "        speeches.append(s)\n",
    "       \n",
    "        labels.append(d[t])\n",
    "        views.append(v)\n",
    "        title.append(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"Creating labels\"></a>\n",
    "\n",
    "## <span style=\"color:#0b486b\">Creating labels in terms of numbers is useful, some functions need them </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating a list of labels in terms on numbers\n",
    "\n",
    "num_label = []\n",
    "for i in labels:\n",
    "    if i ==\"s\":\n",
    "        num_label.append(0)\n",
    "    if i ==\"t\":\n",
    "        num_label.append(1)\n",
    "    if i ==\"b\":\n",
    "        num_label.append(2)\n",
    "    if i ==\"g\":\n",
    "        num_label.append(3)\n",
    "    if i ==s:\n",
    "        num_label.append(3)\n",
    "    if i ==\"e\":\n",
    "        num_label.append(4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"Counting\"></a>\n",
    "\n",
    "## <span style=\"color:#0b486b\">Counting functions for EDA</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_pause(speeches):\n",
    "    counts = []\n",
    "    for s in speeches:\n",
    "        counts.append(s.count(\"--\")+s.count(\" --\")+s.count(\"-- \"))\n",
    "    return counts  \n",
    "def count_questions(speeches):\n",
    "    counts= []\n",
    "    for s in speeches:\n",
    "        counts.append(s.count(\"?\")+s.count(\" ?\")+s.count(\"? \"))\n",
    "    return counts \n",
    "def count_laughters(speeches):\n",
    "    counts= []\n",
    "    for s in speeches:\n",
    "        counts.append(s.count(\"(laughter)\")+s.count(\"laughter\"))\n",
    "    return counts \n",
    "def count_applause(speeches):\n",
    "    counts= []\n",
    "    for s in speeches:\n",
    "        counts.append(s.count(\"(applause)\")+s.count(\"applause\"))\n",
    "    return counts \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "views = np.array(views).astype(int)\n",
    "d_ = {\"views\":views,\"labels\":labels,'sentiment':senti,'pause': count_pause(speeches), 'questions': count_questions(speeches),'laughter':count_laughters(speeches),\"applause\":count_applause(speeches)}\n",
    "df_eda = pd.DataFrame(data=d_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"EDA\"></a>\n",
    "\n",
    "## <span style=\"color:#0b486b\">EDA and summary stats</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_ = df_eda.groupby(\"labels\").sum()\n",
    "df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(1,2,1)\n",
    "sns.barplot([\"business\",\"entertainment\",\"global\",\"science\",\"tech\"],df_.views)\n",
    "plt.title(\"views\")\n",
    "plt.subplot(1,2,2)\n",
    "sns.barplot([\"business\",\"entertainment\",\"global\",\"science\",\"tech\"],df_.sentiment)\n",
    "plt.title(\"sentiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,9))\n",
    "plt.subplot(2,2,1)\n",
    "sns.barplot([\"business\",\"entertainment\",\"global\",\"science\",\"tech\"],df_.laughter)\n",
    "plt.title(\"laughter\")\n",
    "plt.subplot(2,2,2)\n",
    "sns.barplot([\"business\",\"entertainment\",\"global\",\"science\",\"tech\"],df_.pause)\n",
    "plt.title(\"pauses\")\n",
    "plt.subplot(2,2,3)\n",
    "sns.barplot([\"business\",\"entertainment\",\"global\",\"science\",\"tech\"],df_.questions)\n",
    "plt.title(\"questions\")\n",
    "plt.subplot(2,2,4)\n",
    "sns.barplot([\"business\",\"entertainment\",\"global\",\"science\",\"tech\"],df_.applause)\n",
    "plt.title(\"applause\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "view = np.array(df_eda.views).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,9))\n",
    "sns.distplot(view);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"Pre-processing\"></a>\n",
    "\n",
    "## <span style=\"color:#0b486b\">Pre-processing</span>\n",
    "\n",
    "\n",
    "1)  encoding\n",
    "\n",
    "2) punctuation and symbols \n",
    "\n",
    "3) stop words removal\n",
    "\n",
    "4) Lemmatization \n",
    "\n",
    "5) POS tagging  retaining NN and NNP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stop_w = stopwords.words(\"english\")\n",
    "stop_w.extend([\"say\",\"we're\",\"said\",\"things\",\"becae\",\"jt\",\"it's\",'one','like','people','going','know',\"that's\",'think','see','really',\"get\",\"would\",\"i'm\",\"don't\",\"us\",\"actually\",\"may\",\"always\",\"found\",\"fact\",\"lost\",\"you've\",\"end\"])\n",
    "stop_w.extend([\"sided\",\"something\",\"thing\",\"got\",\"also\",\"we've\",\"there's\",\"time\",\"well\",\"way\",\"want\",\"could\",\"first\",\"two\",\"new\",\"they're\",\"you're\",\"take\",\"back\",\"need\",\"many\",\"kind\",\"ever\",\"four\",\"five\",\"used\",\"maybe\",\"start\"])\n",
    "stop_w.extend([\"go\",\"right\",\"make\",\"look\",\"much\",\"even\",\"little\",\"good\",\"work\",\"lot\",\"put\",\"use\",\"three\",\"come\",\"around\",\"different\",\"another\",\"i'll\",\"ask\",\"took\",\"came\",\"tell\",\"great\",\"find\",\"i've\",\"give\",\"went\",\"called\",\"didn't\",\"talk\"])\n",
    "stop_w.extend([\"every\",\"thank\",\"day\",\"big\",\"can't\",\"made\",\"started\",\"still\",\"might\",\"let's\",\"idea\",\"000\",\"what's\",\"years\",\"year\",\"able\",\"start\",\"example\",\"question\",\"show\",\"problem\",\"next\",\"part\",\"let\",\"ago\",\"doesn't\",\"he's\",\"here's\",\"help\"])\n",
    "stop_w.extend([\"almost\",\"living\",\"none\",\"we'd\",\"people's\",\"using\",\"says\",\"okay\",\"yet\",\"10\",\"second\",\"i'd\",\"goes\",\"try\",\"point\",\"20\",\"without\",\"getting\",\"happen\",\"anything\",\"else\",\"wheather\",\"true\",\"ok\",\"30\",\"isn't\",\"per\",\"given\",\"others\",\"we'll\",\"wouldn't\",\"size\",\"who's\"])\n",
    "stop_w.extend([\"yeah\",\"simple\",\"laughing\",\"laughter\",\"(laughter)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(allt, 'r', encoding='utf-8') as f:\n",
    "    talks = ftfy.fix_text(f.read()).split(\"\\n\\n\\n\\n\")\n",
    "\n",
    "talks = list(set((talks)))\n",
    "lemma = WordNetLemmatizer()\n",
    "views = []\n",
    "speeches = []\n",
    "title = []\n",
    "labels = []\n",
    "talks.remove(\"\")\n",
    "\n",
    "for talk in talks:\n",
    "    \n",
    "\n",
    "\n",
    "    h,s = talk.lower().split(\"\\n\\n\")\n",
    "    \n",
    "    t,v = h.split(\"\\n\")\n",
    "    \n",
    "    if t in d:\n",
    "        \n",
    "        #BASIC PUNCTUATION REMOVAL\n",
    "        \n",
    "        s = s.replace(\". \",\" \").replace(\", \",\" \").replace(\",\",\" \").replace(\".\",\" \").replace(\"  \",\" \").replace('\"',\" \")\n",
    "        s = s.replace(\"-- \",\" \").replace(\" --\",\" \").replace(\"? \",\" \").replace(\"?\",\" \").replace(\"  \",\" \")\n",
    "        s = re.sub(r\"\\((.\\w+)\\)\",\"\",s)\n",
    "        \n",
    "        #STOP WORDS removal and LEMMATIZING\n",
    "        \n",
    "        s = \" \".join(lemma.lemmatize(i) for i in s.split() if i not in stop_w)\n",
    "        \n",
    "    \n",
    "        words,tag = zip(*pos_tag(s.split()))\n",
    "        # POS tagging \n",
    "        index = set(np.where(np.array(tag)==\"NN\")[0])\n",
    "        np_index = set(np.where(np.array(tag)==\"NNP\")[0])\n",
    "        index = list(index.union(np_index))\n",
    " \n",
    "        words = np.array(words)[index]\n",
    "        s = \" \".join(i for i in words)\n",
    "        speeches.append(s)\n",
    "       \n",
    "        labels.append(d[t])\n",
    "        views.append(v)\n",
    "        title.append(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"Checking\"></a>\n",
    "\n",
    "## <span style=\"color:#0b486b\">Checking the word counts for better understanding</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "c = Counter()\n",
    "#for each speech\n",
    "for s in speeches:\n",
    "    # counter for words\n",
    "    c += Counter(s.split())\n",
    "from operator import itemgetter\n",
    "sorted_ = sorted(c.items(),key = itemgetter(1),reverse=True)[:10]\n",
    "w,c = zip(*sorted_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"Plotting\"></a>\n",
    "\n",
    "## <span style=\"color:#0b486b\">Plotting the word counts </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indexes = np.arange(len(w))\n",
    "width = 1\n",
    "\n",
    "plt.bar(indexes, c, width)\n",
    "plt.xticks(indexes + width * 0.5, w)\n",
    "plt.title(\"word count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"Count Vectorizer\"></a>\n",
    "\n",
    "## <span style=\"color:#0b486b\">Count Vectorizer, Tfidf vectorizer</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(speeches)\n",
    "df.columns=[\"speeches\"]\n",
    "df[\"labels\"]=labels\n",
    "# TFIDF VECTORIZER\n",
    "\n",
    "tfidf_model =TfidfVectorizer(max_df=0.95 , min_df=2  , stop_words=stop_w)\n",
    "\n",
    "vectorized_tfidf = tfidf_model.fit_transform(df.speeches)\n",
    "\n",
    "#COUNT VECTORIZER\n",
    "\n",
    "tf_model =CountVectorizer(max_df=0.95 , min_df=2  , stop_words=stop_w)\n",
    "\n",
    "vectorized_tf = tf_model.fit_transform(df.speeches)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"Visualizing\"></a>\n",
    "\n",
    "## <span style=\"color:#0b486b\">Visualizing the TFIDF vectors using a manifold similarity between document vectors</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dist = 1 - cosine_similarity(vectorized_tfidf)\n",
    "MDS()\n",
    "\n",
    "# convert two components as we're plotting points in a two-dimensional plane\n",
    "# \"precomputed\" because we provide a distance matrix\n",
    "# we will also specify `random_state` so the plot is reproducible.\n",
    "mds = MDS(n_components=3, dissimilarity=\"precomputed\", random_state=1)\n",
    "\n",
    "pos = mds.fit_transform(dist)  # shape (n_components, n_samples)\n",
    "\n",
    "xs, ys, zs = pos[:, 0], pos[:, 1],pos[:,2]\n",
    "\n",
    "fig = pylab.figure(figsize=(10,7))\n",
    "ax = fig.add_subplot(111, projection =\"3d\")\n",
    "sc = ax.scatter(xs,ys,zs,c=num_label,cmap=plt.cm.rainbow)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Visualizing the similarities among the document vectors. There is no clear pattern , but we will see by the end of the project that the doc2vec document vectors will make more sense. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"Running LDA \"></a>\n",
    "\n",
    "## <span style=\"color:#0b486b\">Running LDA on count vectorized documents</span>\n",
    "LDA on count vectorized vectors gave better results as compared to LDA on TFIDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# build LDA model\n",
    "\n",
    "lda = LatentDirichletAllocation(n_topics=5,\n",
    "                                max_iter=5,\n",
    "                                learning_method='online',\n",
    "                                learning_offset=50.,\n",
    "                                random_state=42)\n",
    "\n",
    "lda.fit(vectorized_tf)\n",
    "topics_words = lda.components_\n",
    "words = tf_model.get_feature_names()\n",
    "\n",
    "# Print the words that represent the topics\n",
    "\n",
    "def print_top_words(model,words,n_top_words=20):\n",
    "    for index,topic in enumerate(model.components_):\n",
    "        print(\"Topic #%d:\" % index)\n",
    "        print(\"|\".join([words[i] for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "print(\"Topics in LDA model:\")\n",
    "tf_feature_names = tf_model.get_feature_names()\n",
    "print_top_words(lda, tf_feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a,b=zip(*nltk.pos_tag(speeches[2].split()))\n",
    "index = np.where(np.array(b)==\"NN\")\n",
    "list(index).extend(np.where(np.array(b)==\"NNP\"))\n",
    "np.array(a)[index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How LDA performs compares to the actual labels that we have :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "v = lda.transform(vectorized_tf)\n",
    "Counter([np.argmax(i) for i in v])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> It doesnt perform that well, we can see that the documents are unevenly distributed among the clusters. But we donot have any class imbalance in our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = 'https://github.com/tulip-lab/mds/raw/master/Jupyter/image/LDA_clusters.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename, width=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pyLDAvis.sklearn.prepare(lda,vectorized_tfidf,tfidf_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"NMF\"></a>\n",
    "\n",
    "## <span style=\"color:#0b486b\">NMF - Topic Modeling using TFIDF </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Build te NMF Model\n",
    "\n",
    "nmf = NMF(init=\"nndsvd\",\n",
    "            n_components=5,\n",
    "            max_iter=200)\n",
    "nmf.fit(vectorized_tfidf)\n",
    "topics_words = nmf.components_\n",
    "words = tfidf_model.get_feature_names()\n",
    "\n",
    "print(\"Topics in NMF model:\")\n",
    "tf_feature_names = tfidf_model.get_feature_names()\n",
    "print_top_words(nmf, tf_feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"Manual\"></a>\n",
    "\n",
    "## <span style=\"color:#0b486b\">Manual labelling of the topics</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0 -->  global\n",
    "\n",
    "1 -->  technology\n",
    "\n",
    "2 -->  science\n",
    "\n",
    "3 --> entertainment\n",
    "\n",
    "4 ---> business\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"Checking\"></a>\n",
    "\n",
    "## <span style=\"color:#0b486b\">Checking performance of Topic Modeling</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "v = nmf.transform(vectorized_tfidf)\n",
    "\n",
    "Counter([np.argmax(i) for i in v])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "highest_weighted_topics = [np.argmax(i) for i in v]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We can see that the documents are almost equally distributed over all the categories, which is how our initial data was divided into categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manually labelling the topics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = []\n",
    "for i in highest_weighted_topics:\n",
    "    if i == 0:\n",
    "        p.append(\"t\") # global issues\n",
    "    if i ==1:\n",
    "        p.append(\"b\") # tech\n",
    "    if i ==2:\n",
    "        p.append(\"s\") # business\n",
    "    if i ==3:\n",
    "        p.append(\"g\") # science\n",
    "    if i ==4:\n",
    "        p.append(\"e\") # entertainment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Note:\n",
    "\n",
    "Make sure you label the topics manually every time you re-run NMF.  \n",
    "\n",
    "NMF assigns random numbers to the topics that it prints. So read the words , label the topics using the previous cell. That is ->   p....    and then check for accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking  for accuracy after doing the labeling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"accuracy of my topic modeling : \",np.round(accuracy_score(labels,p)*100),\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting an accuracy of 44% which is better than most of the classifiers that I tried on the tfidf matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing the NMF model: There is a clear seperation between the topics, and they all make perfect sense when we examine the words in each topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NMF_filename = 'https://github.com/tulip-lab/mds/raw/master/Jupyter/image/NMF_clusters.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(NMF_filename, width=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pyLDAvis.sklearn.prepare(nmf,vectorized_tfidf,tfidf_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"Default LDA\"></a>\n",
    "\n",
    "## <span style=\"color:#0b486b\">Default LDA</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "X_train, X_test, y_train, y_test = train_test_split(vectorized_tfidf, labels, test_size=.5,random_state=0)\n",
    "lda_ =  LinearDiscriminantAnalysis()\n",
    "lda_.fit(X_train.toarray(),y_train)\n",
    "y_pred = lda_.predict(X_test)\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conf = pd.DataFrame(confusion_matrix(y_true=y_test,y_pred=y_pred))\n",
    "conf.columns = [\"business\",\"entertain\",\"global\",\"science\",\"tech\"]\n",
    "conf.index = [\"business\",\"entertain\",\"global\",\"science\",\"tech\"]\n",
    "conf.columns.name = \"True\\Predicted\"\n",
    "conf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"ROC \"></a>\n",
    "\n",
    "## <span style=\"color:#0b486b\">ROC </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = label_binarize(num_label, classes=[0, 1, 2, 3, 4])\n",
    "n_classes = y.shape[1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.speeches, y, test_size=.5,random_state=0)\n",
    "cv = CountVectorizer()\n",
    "cv.fit(X_train)\n",
    "X_train,X_test = cv.transform(X_train),cv.transform(X_test)\n",
    "classifier = OneVsRestClassifier(LinearDiscriminantAnalysis())\n",
    "y_score = classifier.fit(X_train.toarray(), y_train).predict_proba(X_test)\n",
    "#y_score[:,0]\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = metrics.roc_curve(y_test[:,i], y_score[:, i])\n",
    "    roc_auc[i] = metrics.auc(fpr[i], tpr[i])\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = metrics.roc_curve(y_test.ravel(), y_score.ravel())\n",
    "roc_auc[\"micro\"] = metrics.auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "plt.figure()\n",
    "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "         label='micro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"micro\"]))\n",
    "for i in range(n_classes):\n",
    "    plt.plot(fpr[i], tpr[i], label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "                                   ''.format(i, roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title(\"Linear Discriminant Analysis\")\n",
    "plt.legend(bbox_to_anchor=(0, 2), loc='upper left', ncol=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------\n",
    "\n",
    "Trying to predict number of views using number of pauses, laughters, applauses, sentiment :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "X = df_eda[[\"pause\",\"questions\",\"laughter\",\"applause\",\"sentiment\"]].values\n",
    "y = np.array(df_eda.views)\n",
    "\n",
    "model = sm.OLS(y.astype(int), X)\n",
    "results = model.fit()\n",
    "results.summary()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [anaconda3]",
   "language": "python",
   "name": "Python [anaconda3]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

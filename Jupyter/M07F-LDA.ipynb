{
    "nbformat_minor": 1, 
    "cells": [
        {
            "source": "# Modern Data Science\n**(Module 07: Natural Language Processing)**\n\n---\n- Materials in this module include resources collected from various open-source online repositories.\n- You are free to use, but NOT allowed to change or distribute this package.\n\nPrepared by and for \n**Student Members** |\n2006-2019 [TULIP Lab](http://www.tulip.org.au)\n\n---", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "# Session F - Topic Model - LDA", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "<a id = \"Computing\"></a>\n\n## <span style=\"color:#0b486b\">Import the packages</span>", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# !pip install textblob\n# !pip install ftfy\n!pip install pyLDAvis"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "from nltk.corpus import stopwords\nfrom nltk import stem,pos_tag\nimport re\nfrom collections import Counter\nimport numpy as np\n%pylab inline\nfrom textblob import TextBlob\nfrom sklearn.metrics import silhouette_score,confusion_matrix,accuracy_score,roc_curve\nimport pandas as pd\nfrom nltk.stem.wordnet import WordNetLemmatizer\nfrom sklearn.cross_validation import train_test_split\nfrom sklearn.preprocessing import label_binarize,Normalizer\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom scipy import interp\nimport ftfy\nimport pyLDAvis.sklearn\npyLDAvis.enable_notebook()\nfrom sklearn.grid_search import GridSearchCV\nimport statsmodels.api as sm\nfrom seaborn import lmplot\nimport os  # for os.path.basename\nimport matplotlib as mpl\nfrom sklearn.manifold import MDS,TSNE\n%pylab inline\nfrom mpl_toolkits.mplot3d import Axes3D\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import BernoulliNB, MultinomialNB\nfrom sklearn.utils.extmath import density\nfrom sklearn import metrics\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\nfrom sklearn.decomposition import TruncatedSVD,PCA,NMF\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.decomposition.online_lda import LatentDirichletAllocation"
        }, 
        {
            "source": "<a id = \"Function\"></a>\n\n## <span style=\"color:#0b486b\">Function to get titles of talks</span>", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "def get_titles_from_talks(talks):\n    \n    title = []\n    # For all the talks in that category\n    for talk in talks:\n        # if the talk is not empty\n        if talk != \"\":\n            # split talk and the header\n            h,s = talk.lower().split(\"\\n\\n\")\n            # Header contains the title and the number of views\n            t,v = h.split(\"\\n\")\n            # Get the titles\n            title.append(t)\n    return title"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "!pip install wget"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "import wget\n\nentertainment = 'https://github.com/tulip-lab/mds/tree/master/Jupyter/data/entertainment.txt?raw=true'\nentertainment = wget.download(entertainment) \n\ntechnology = 'https://github.com/tulip-lab/mds/tree/master/Jupyter/data/technology.txt?raw=true'\ntechnology = wget.download(technology) \n\nscience  = 'https://github.com/tulip-lab/mds/tree/master/Jupyter/data/science.txt?raw=true'\nscience = wget.download(science) \n\nbusiness = 'https://github.com/tulip-lab/mds/tree/master/Jupyter/data/business.txt?raw=true'\nbusiness = wget.download(business) \n\nglobal_issues = 'https://github.com/tulip-lab/mds/tree/master/Jupyter/data/global_issues.txt?raw=true'\nglobal_issues = wget.download(global_issues) "
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "with open(entertainment, 'r', encoding='utf-8') as f:\n    talks = ftfy.fix_text(f.read()).split(\"\\n\\n\\n\\n\")\n    \ntalks= list(set((talks)))\n       \nent = get_titles_from_talks(talks)\n\n\n\nwith open(technology, 'r', encoding='utf-8') as f:\n    talks = ftfy.fix_text(f.read()).split(\"\\n\\n\\n\\n\")\n    \ntalks = list(set((talks)))\n       \ntech = get_titles_from_talks(talks)\n\n\n\n\nwith open(science, 'r', encoding='utf-8') as f:\n    talks = ftfy.fix_text(f.read()).split(\"\\n\\n\\n\\n\")\n    \ntalks = list(set((talks)))\n       \nscience = get_titles_from_talks(talks)\n\n\n\n\nwith open(business, 'r', encoding='utf-8') as f:\n    talks = ftfy.fix_text(f.read()).split(\"\\n\\n\\n\\n\")\n    \ntalks = list(set((talks)))\n       \nbusiness = get_titles_from_talks(talks)\n\n\n\n\nwith open(global_issues, 'r', encoding='utf-8') as f:\n    talks = ftfy.fix_text(f.read()).split(\"\\n\\n\\n\\n\")\n    \ntalks = list(set((talks)))\n       \nglob = get_titles_from_talks(talks)"
        }, 
        {
            "source": "<a id = \"Getting\"></a>\n\n## <span style=\"color:#0b486b\">Getting the talks that occur only once over the whole corpus.</span>", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "topic_c = Counter()\n# loop over all the talk-titles in each of the category\nfor topic in [ent,tech,glob,business,science]:\n    #increment the counter for that title if it occurs more than once\n    topic_c += Counter(topic)\n# unzip the counter object\ntopic,c = zip(*topic_c.items())\n# select the talks that only occur once\ntitles = np.array(topic)[np.where(np.array(c)==1)]\n"
        }, 
        {
            "source": "\n### These single letter labels make it easy to unserstand the output in some places\n\ns -> science --- 0\n\nt -> Technology --- 1\n\nb ->business --- 2\n\ng ->global --- 3\n\ne -> entertainment ---4\n\n<a id = \"Creating\"></a>\n\n## <span style=\"color:#0b486b\">Creating a dictionary of labels for all the talks</span>\n\n\n### These are the actual labels : I'm getting them beacuse I'm loading talks category wise.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "d = {}\n\nfor title in titles:\n    if title in tech:  # Talks in technology  have title \"t\"\n        d[title]=\"t\"\n    if title in ent:# Talks in entertainment  have title \"e\"\n        d[title]=\"e\"\n    if title in business: # Talks in business  have title \"b\"\n        d[title]=\"b\"\n    if title in glob: # Talks in global issues  have title \"g\"\n        d[title]=\"g\"\n    if title in science: # Talks in science  have title \"s\"\n        d[title]=\"s\""
        }, 
        {
            "source": "<a id = \"Category\"></a>\n\n## <span style=\"color:#0b486b\">Category sizes/splits :</span>\n\nbusiness = 123\n\nentertainment = 152\n\nglobal issues = 245\n\nscience = 209\n\ntechnology = 249", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "Counter(d.values())"
        }, 
        {
            "source": "----", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "### we donot have much class imbalance. \n\n### Base line accuracy is 25-30%", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "-----", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "<a id = \"Loading\"></a>\n\n## <span style=\"color:#0b486b\">Loading all the documents together, retaining all the punctuations to get a proper count of pauses and question marks for EDA</span>", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "allt =  'https://github.com/tulip-lab/mds/tree/master/Jupyter/data/all.txt?raw=true'\nallt = wget.download(allt) "
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "!pip install nltk"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "import nltk"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "nltk.download()"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "#Loading the file that contains all the talks. These belong to all the categories that we have\nwith open(allt, 'r', encoding='utf-8') as f:\n    talks = ftfy.fix_text(f.read()).split(\"\\n\\n\\n\\n\")\n\ntalks = list(set((talks)))\nlemma = WordNetLemmatizer()\nstop_w = stopwords.words(\"english\")\nviews = []\nspeeches = []\ntitle = []\nlabels = []\nsenti = []\ntalks.remove(\"\")\n\n# loop over talks\nfor talk in talks:\n    \n\n    # Split the header and the actual speech\n    h,s = talk.lower().split(\"\\n\\n\")\n    #split the header , that contains title and the views\n    t,v = h.split(\"\\n\")\n    # If that title is predent in the talks that are unique , which we computed earlier\n    if t in d:\n        # some punctuation removal\n        s = s.replace(\". \",\" \").replace(\", \",\" \").replace(\",\",\" \").replace(\".\",\" \").replace(\"  \",\" \").replace('\"',\" \")\n\n        # removing stop words\n        s = \" \".join(i for i in s.split() if i not in stop_w)\n        \n        f = TextBlob(s)\n        senti.append(f.polarity)\n        \n        speeches.append(s)\n       \n        labels.append(d[t])\n        views.append(v)\n        title.append(t)"
        }, 
        {
            "source": "<a id = \"Creating labels\"></a>\n\n## <span style=\"color:#0b486b\">Creating labels in terms of numbers is useful, some functions need them </span>", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# Creating a list of labels in terms on numbers\n\nnum_label = []\nfor i in labels:\n    if i ==\"s\":\n        num_label.append(0)\n    if i ==\"t\":\n        num_label.append(1)\n    if i ==\"b\":\n        num_label.append(2)\n    if i ==\"g\":\n        num_label.append(3)\n    if i ==s:\n        num_label.append(3)\n    if i ==\"e\":\n        num_label.append(4)\n"
        }, 
        {
            "source": "<a id = \"Counting\"></a>\n\n## <span style=\"color:#0b486b\">Counting functions for EDA</span>", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "def count_pause(speeches):\n    counts = []\n    for s in speeches:\n        counts.append(s.count(\"--\")+s.count(\" --\")+s.count(\"-- \"))\n    return counts  \ndef count_questions(speeches):\n    counts= []\n    for s in speeches:\n        counts.append(s.count(\"?\")+s.count(\" ?\")+s.count(\"? \"))\n    return counts \ndef count_laughters(speeches):\n    counts= []\n    for s in speeches:\n        counts.append(s.count(\"(laughter)\")+s.count(\"laughter\"))\n    return counts \ndef count_applause(speeches):\n    counts= []\n    for s in speeches:\n        counts.append(s.count(\"(applause)\")+s.count(\"applause\"))\n    return counts \n"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "views = np.array(views).astype(int)\nd_ = {\"views\":views,\"labels\":labels,'sentiment':senti,'pause': count_pause(speeches), 'questions': count_questions(speeches),'laughter':count_laughters(speeches),\"applause\":count_applause(speeches)}\ndf_eda = pd.DataFrame(data=d_)"
        }, 
        {
            "source": "<a id = \"EDA\"></a>\n\n## <span style=\"color:#0b486b\">EDA and summary stats</span>", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "df_ = df_eda.groupby(\"labels\").sum()\ndf_"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "import seaborn as sns\nplt.figure(figsize=(15,5))\nplt.subplot(1,2,1)\nsns.barplot([\"business\",\"entertainment\",\"global\",\"science\",\"tech\"],df_.views)\nplt.title(\"views\")\nplt.subplot(1,2,2)\nsns.barplot([\"business\",\"entertainment\",\"global\",\"science\",\"tech\"],df_.sentiment)\nplt.title(\"sentiment\")"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "plt.figure(figsize=(12,9))\nplt.subplot(2,2,1)\nsns.barplot([\"business\",\"entertainment\",\"global\",\"science\",\"tech\"],df_.laughter)\nplt.title(\"laughter\")\nplt.subplot(2,2,2)\nsns.barplot([\"business\",\"entertainment\",\"global\",\"science\",\"tech\"],df_.pause)\nplt.title(\"pauses\")\nplt.subplot(2,2,3)\nsns.barplot([\"business\",\"entertainment\",\"global\",\"science\",\"tech\"],df_.questions)\nplt.title(\"questions\")\nplt.subplot(2,2,4)\nsns.barplot([\"business\",\"entertainment\",\"global\",\"science\",\"tech\"],df_.applause)\nplt.title(\"applause\")\nplt.tight_layout()"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "view = np.array(df_eda.views).astype(int)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "plt.figure(figsize=(12,9))\nsns.distplot(view);"
        }, 
        {
            "source": "<a id = \"Pre-processing\"></a>\n\n## <span style=\"color:#0b486b\">Pre-processing</span>\n\n\n1)  encoding\n\n2) punctuation and symbols \n\n3) stop words removal\n\n4) Lemmatization \n\n5) POS tagging  retaining NN and NNP\n", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "stop_w = stopwords.words(\"english\")\nstop_w.extend([\"say\",\"we're\",\"said\",\"things\",\"becae\",\"jt\",\"it's\",'one','like','people','going','know',\"that's\",'think','see','really',\"get\",\"would\",\"i'm\",\"don't\",\"us\",\"actually\",\"may\",\"always\",\"found\",\"fact\",\"lost\",\"you've\",\"end\"])\nstop_w.extend([\"sided\",\"something\",\"thing\",\"got\",\"also\",\"we've\",\"there's\",\"time\",\"well\",\"way\",\"want\",\"could\",\"first\",\"two\",\"new\",\"they're\",\"you're\",\"take\",\"back\",\"need\",\"many\",\"kind\",\"ever\",\"four\",\"five\",\"used\",\"maybe\",\"start\"])\nstop_w.extend([\"go\",\"right\",\"make\",\"look\",\"much\",\"even\",\"little\",\"good\",\"work\",\"lot\",\"put\",\"use\",\"three\",\"come\",\"around\",\"different\",\"another\",\"i'll\",\"ask\",\"took\",\"came\",\"tell\",\"great\",\"find\",\"i've\",\"give\",\"went\",\"called\",\"didn't\",\"talk\"])\nstop_w.extend([\"every\",\"thank\",\"day\",\"big\",\"can't\",\"made\",\"started\",\"still\",\"might\",\"let's\",\"idea\",\"000\",\"what's\",\"years\",\"year\",\"able\",\"start\",\"example\",\"question\",\"show\",\"problem\",\"next\",\"part\",\"let\",\"ago\",\"doesn't\",\"he's\",\"here's\",\"help\"])\nstop_w.extend([\"almost\",\"living\",\"none\",\"we'd\",\"people's\",\"using\",\"says\",\"okay\",\"yet\",\"10\",\"second\",\"i'd\",\"goes\",\"try\",\"point\",\"20\",\"without\",\"getting\",\"happen\",\"anything\",\"else\",\"wheather\",\"true\",\"ok\",\"30\",\"isn't\",\"per\",\"given\",\"others\",\"we'll\",\"wouldn't\",\"size\",\"who's\"])\nstop_w.extend([\"yeah\",\"simple\",\"laughing\",\"laughter\",\"(laughter)\"])"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "with open(allt, 'r', encoding='utf-8') as f:\n    talks = ftfy.fix_text(f.read()).split(\"\\n\\n\\n\\n\")\n\ntalks = list(set((talks)))\nlemma = WordNetLemmatizer()\nviews = []\nspeeches = []\ntitle = []\nlabels = []\ntalks.remove(\"\")\n\nfor talk in talks:\n    \n\n\n    h,s = talk.lower().split(\"\\n\\n\")\n    \n    t,v = h.split(\"\\n\")\n    \n    if t in d:\n        \n        #BASIC PUNCTUATION REMOVAL\n        \n        s = s.replace(\". \",\" \").replace(\", \",\" \").replace(\",\",\" \").replace(\".\",\" \").replace(\"  \",\" \").replace('\"',\" \")\n        s = s.replace(\"-- \",\" \").replace(\" --\",\" \").replace(\"? \",\" \").replace(\"?\",\" \").replace(\"  \",\" \")\n        s = re.sub(r\"\\((.\\w+)\\)\",\"\",s)\n        \n        #STOP WORDS removal and LEMMATIZING\n        \n        s = \" \".join(lemma.lemmatize(i) for i in s.split() if i not in stop_w)\n        \n    \n        words,tag = zip(*pos_tag(s.split()))\n        # POS tagging \n        index = set(np.where(np.array(tag)==\"NN\")[0])\n        np_index = set(np.where(np.array(tag)==\"NNP\")[0])\n        index = list(index.union(np_index))\n \n        words = np.array(words)[index]\n        s = \" \".join(i for i in words)\n        speeches.append(s)\n       \n        labels.append(d[t])\n        views.append(v)\n        title.append(t)"
        }, 
        {
            "source": "<a id = \"Checking\"></a>\n\n## <span style=\"color:#0b486b\">Checking the word counts for better understanding</span>", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": false
            }, 
            "outputs": [], 
            "source": "c = Counter()\n#for each speech\nfor s in speeches:\n    # counter for words\n    c += Counter(s.split())\nfrom operator import itemgetter\nsorted_ = sorted(c.items(),key = itemgetter(1),reverse=True)[:10]\nw,c = zip(*sorted_)"
        }, 
        {
            "source": "<a id = \"Plotting\"></a>\n\n## <span style=\"color:#0b486b\">Plotting the word counts </span>", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "indexes = np.arange(len(w))\nwidth = 1\n\nplt.bar(indexes, c, width)\nplt.xticks(indexes + width * 0.5, w)\nplt.title(\"word count\")\nplt.show()"
        }, 
        {
            "source": "<a id = \"Count Vectorizer\"></a>\n\n## <span style=\"color:#0b486b\">Count Vectorizer, Tfidf vectorizer</span>", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "df = pd.DataFrame(speeches)\ndf.columns=[\"speeches\"]\ndf[\"labels\"]=labels\n# TFIDF VECTORIZER\n\ntfidf_model =TfidfVectorizer(max_df=0.95 , min_df=2  , stop_words=stop_w)\n\nvectorized_tfidf = tfidf_model.fit_transform(df.speeches)\n\n#COUNT VECTORIZER\n\ntf_model =CountVectorizer(max_df=0.95 , min_df=2  , stop_words=stop_w)\n\nvectorized_tf = tf_model.fit_transform(df.speeches)\n"
        }, 
        {
            "source": "<a id = \"Visualizing\"></a>\n\n## <span style=\"color:#0b486b\">Visualizing the TFIDF vectors using a manifold similarity between document vectors</span>", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "dist = 1 - cosine_similarity(vectorized_tfidf)\nMDS()\n\n# convert two components as we're plotting points in a two-dimensional plane\n# \"precomputed\" because we provide a distance matrix\n# we will also specify `random_state` so the plot is reproducible.\nmds = MDS(n_components=3, dissimilarity=\"precomputed\", random_state=1)\n\npos = mds.fit_transform(dist)  # shape (n_components, n_samples)\n\nxs, ys, zs = pos[:, 0], pos[:, 1],pos[:,2]\n\nfig = pylab.figure(figsize=(10,7))\nax = fig.add_subplot(111, projection =\"3d\")\nsc = ax.scatter(xs,ys,zs,c=num_label,cmap=plt.cm.rainbow)\n"
        }, 
        {
            "source": "> Visualizing the similarities among the document vectors. There is no clear pattern , but we will see by the end of the project that the doc2vec document vectors will make more sense. ", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "<a id = \"Running LDA \"></a>\n\n## <span style=\"color:#0b486b\">Running LDA on count vectorized documents</span>\nLDA on count vectorized vectors gave better results as compared to LDA on TFIDF.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": false
            }, 
            "outputs": [], 
            "source": "# build LDA model\n\nlda = LatentDirichletAllocation(n_topics=5,\n                                max_iter=5,\n                                learning_method='online',\n                                learning_offset=50.,\n                                random_state=42)\n\nlda.fit(vectorized_tf)\ntopics_words = lda.components_\nwords = tf_model.get_feature_names()\n\n# Print the words that represent the topics\n\ndef print_top_words(model,words,n_top_words=20):\n    for index,topic in enumerate(model.components_):\n        print(\"Topic #%d:\" % index)\n        print(\"|\".join([words[i] for i in topic.argsort()[:-n_top_words - 1:-1]]))\nprint(\"Topics in LDA model:\")\ntf_feature_names = tf_model.get_feature_names()\nprint_top_words(lda, tf_feature_names)"
        }, 
        {
            "source": "a,b=zip(*nltk.pos_tag(speeches[2].split()))\nindex = np.where(np.array(b)==\"NN\")\nlist(index).extend(np.where(np.array(b)==\"NNP\"))\nnp.array(a)[index]", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "How LDA performs compares to the actual labels that we have :", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "v = lda.transform(vectorized_tf)\nCounter([np.argmax(i) for i in v])"
        }, 
        {
            "source": "> It doesnt perform that well, we can see that the documents are unevenly distributed among the clusters. But we donot have any class imbalance in our data.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "filename = 'https://github.com/tulip-lab/mds/raw/master/Jupyter/image/LDA_clusters.png'"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "from IPython.display import Image\nImage(filename, width=1000)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "pyLDAvis.sklearn.prepare(lda,vectorized_tfidf,tfidf_model)"
        }, 
        {
            "source": "<a id = \"NMF\"></a>\n\n## <span style=\"color:#0b486b\">NMF - Topic Modeling using TFIDF </span>", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "#Build te NMF Model\n\nnmf = NMF(init=\"nndsvd\",\n            n_components=5,\n            max_iter=200)\nnmf.fit(vectorized_tfidf)\ntopics_words = nmf.components_\nwords = tfidf_model.get_feature_names()\n\nprint(\"Topics in NMF model:\")\ntf_feature_names = tfidf_model.get_feature_names()\nprint_top_words(nmf, tf_feature_names)"
        }, 
        {
            "source": "<a id = \"Manual\"></a>\n\n## <span style=\"color:#0b486b\">Manual labelling of the topics</span>", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "0 -->  global\n\n1 -->  technology\n\n2 -->  science\n\n3 --> entertainment\n\n4 ---> business\n", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "<a id = \"Checking\"></a>\n\n## <span style=\"color:#0b486b\">Checking performance of Topic Modeling</span>", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "v = nmf.transform(vectorized_tfidf)\n\nCounter([np.argmax(i) for i in v])"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "highest_weighted_topics = [np.argmax(i) for i in v]"
        }, 
        {
            "source": "> We can see that the documents are almost equally distributed over all the categories, which is how our initial data was divided into categories", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "### Manually labelling the topics ", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "p = []\nfor i in highest_weighted_topics:\n    if i == 0:\n        p.append(\"t\") # global issues\n    if i ==1:\n        p.append(\"b\") # tech\n    if i ==2:\n        p.append(\"s\") # business\n    if i ==3:\n        p.append(\"g\") # science\n    if i ==4:\n        p.append(\"e\") # entertainment\n"
        }, 
        {
            "source": "** Note:\n\nMake sure you label the topics manually every time you re-run NMF.  \n\nNMF assigns random numbers to the topics that it prints. So read the words , label the topics using the previous cell. That is ->   p....    and then check for accuracy", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "Checking  for accuracy after doing the labeling ", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "print(\"accuracy of my topic modeling : \",np.round(accuracy_score(labels,p)*100),\"%\")"
        }, 
        {
            "source": "Getting an accuracy of 44% which is better than most of the classifiers that I tried on the tfidf matrix.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "Visualizing the NMF model: There is a clear seperation between the topics, and they all make perfect sense when we examine the words in each topic.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "NMF_filename = 'https://github.com/tulip-lab/mds/raw/master/Jupyter/image/NMF_clusters.png'"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "from IPython.display import Image\nImage(NMF_filename, width=1000)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "pyLDAvis.sklearn.prepare(nmf,vectorized_tfidf,tfidf_model)"
        }, 
        {
            "source": "<a id = \"Default LDA\"></a>\n\n## <span style=\"color:#0b486b\">Default LDA</span>", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nX_train, X_test, y_train, y_test = train_test_split(vectorized_tfidf, labels, test_size=.5,random_state=0)\nlda_ =  LinearDiscriminantAnalysis()\nlda_.fit(X_train.toarray(),y_train)\ny_pred = lda_.predict(X_test)\naccuracy_score(y_test,y_pred)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "conf = pd.DataFrame(confusion_matrix(y_true=y_test,y_pred=y_pred))\nconf.columns = [\"business\",\"entertain\",\"global\",\"science\",\"tech\"]\nconf.index = [\"business\",\"entertain\",\"global\",\"science\",\"tech\"]\nconf.columns.name = \"True\\Predicted\"\nconf"
        }, 
        {
            "source": "<a id = \"ROC \"></a>\n\n## <span style=\"color:#0b486b\">ROC </span>", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "y = label_binarize(num_label, classes=[0, 1, 2, 3, 4])\nn_classes = y.shape[1]\nX_train, X_test, y_train, y_test = train_test_split(df.speeches, y, test_size=.5,random_state=0)\ncv = CountVectorizer()\ncv.fit(X_train)\nX_train,X_test = cv.transform(X_train),cv.transform(X_test)\nclassifier = OneVsRestClassifier(LinearDiscriminantAnalysis())\ny_score = classifier.fit(X_train.toarray(), y_train).predict_proba(X_test)\n#y_score[:,0]\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\nfor i in range(n_classes):\n    fpr[i], tpr[i], _ = metrics.roc_curve(y_test[:,i], y_score[:, i])\n    roc_auc[i] = metrics.auc(fpr[i], tpr[i])\nfpr[\"micro\"], tpr[\"micro\"], _ = metrics.roc_curve(y_test.ravel(), y_score.ravel())\nroc_auc[\"micro\"] = metrics.auc(fpr[\"micro\"], tpr[\"micro\"])\nplt.figure()\nplt.plot(fpr[\"micro\"], tpr[\"micro\"],\n         label='micro-average ROC curve (area = {0:0.2f})'\n               ''.format(roc_auc[\"micro\"]))\nfor i in range(n_classes):\n    plt.plot(fpr[i], tpr[i], label='ROC curve of class {0} (area = {1:0.2f})'\n                                   ''.format(i, roc_auc[i]))\n\nplt.plot([0, 1], [0, 1], 'k--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title(\"Linear Discriminant Analysis\")\nplt.legend(bbox_to_anchor=(0, 2), loc='upper left', ncol=1)\nplt.show()"
        }, 
        {
            "source": "----------------------\n\nTrying to predict number of views using number of pauses, laughters, applauses, sentiment :", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "\nX = df_eda[[\"pause\",\"questions\",\"laughter\",\"applause\",\"sentiment\"]].values\ny = np.array(df_eda.views)\n\nmodel = sm.OLS(y.astype(int), X)\nresults = model.fit()\nresults.summary()"
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.5", 
            "name": "python3", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.5.5", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython3", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }, 
        "anaconda-cloud": {}
    }, 
    "nbformat": 4
}